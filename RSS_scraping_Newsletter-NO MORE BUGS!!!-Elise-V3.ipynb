{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2019-10-23\n"
     ]
    }
   ],
   "source": [
    "import feedparser as fp\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "import time\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import json\n",
    "import pprint\n",
    "import dateutil\n",
    "\n",
    "#### 1 Website data ####\n",
    "\n",
    "## 1A ##  From JSON file - for final version\n",
    "\n",
    "#with open('NewsPapers.json') as data_file: #Loads the JSON files with news URLs\n",
    "#    companies = json.load(data_file)\n",
    "\n",
    "## 1B ## From variable - this is for testing, makes it way faster\n",
    "website = {\"cnn\": {\"link\": \"http://edition.cnn.com/\", \"rss\": \"http://rss.cnn.com/rss/cnn_topstories.rss\"},\n",
    "          \"cnbc\":{\"link\": \"https://www.cnbc.com/\", \"rss\": \"https://www.cnbc.com/id/10000664/device/rss/rss.html\"}}\n",
    "\n",
    "\n",
    "#### 2 Todays date - for filtering the articles ####\n",
    "today = str(date.today()) \n",
    "print(\"Today's date:\", today)\n",
    "\n",
    "\n",
    "#### 3 Scraping the news articles ####\n",
    "\n",
    "article_list = []\n",
    "date_list = []\n",
    "time_list = []\n",
    "title_list = []\n",
    "\n",
    "for source, value in website.items():\n",
    "    if 'rss' in value:\n",
    "        d = fp.parse(value['rss']) #if there is an RSS value for a company in the website data, it will be extracted into d\n",
    "        article={}\n",
    "        \n",
    "        for entry in d.entries:\n",
    "            if hasattr(entry, 'published'):\n",
    "                \n",
    "                #getting the article URLs\n",
    "                article['link'] = entry.link\n",
    "                article_list.append(article['link'])\n",
    "                \n",
    "                #getting the article published dates\n",
    "                date = (getattr(entry, 'published'))\n",
    "                date = dateutil.parser.parse(date)\n",
    "                date_formated = date.strftime(\"%Y-%m-%d\")\n",
    "                time_formated = date.strftime(\"%H:%M:%S %Z\") #hour, minute, timezone (converted)\n",
    "                date_list.append(date_formated)\n",
    "                time_list.append(time_formated)\n",
    "                \n",
    "                #getting the titles\n",
    "                content = Article(entry.link)\n",
    "                try:\n",
    "                    content.download() #downloading article content\n",
    "                    #downloading takes approx. 3min to load\n",
    "                    content.parse()                    \n",
    "                except Exception as e: \n",
    "                    #in case the download fails, it prints the error and immediatly continues with downloading the next article\n",
    "                    print(e)\n",
    "                    print(\"continuing...\")\n",
    "                title = content.title #extract article titles\n",
    "                title_list.append(title)\n",
    "                \n",
    "#creating dicts for formatting and inserting to pandas df\n",
    "link_dict = {'link':article_list}\n",
    "date_dict = {'published_date':date_list}\n",
    "time_dict = {'published_time':time_list}\n",
    "title_dict = {'title':title_list}\n",
    "\n",
    "#creating separate pandas dfs for each feature\n",
    "link_df = pd.DataFrame(link_dict)\n",
    "date_df = pd.DataFrame(date_dict)\n",
    "time_df = pd.DataFrame(time_dict)\n",
    "title_df = pd.DataFrame(title_dict)\n",
    "\n",
    "#join all pandas dfs together\n",
    "news_df = link_df.join(date_df)\n",
    "news_df = news_df.join(time_df)\n",
    "news_df = news_df.join(title_df)\n",
    "\n",
    "#after 3 min, pandas DF sould be created with link, published_date, published_time and title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_time</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_topstories/~3/md...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>18:09:23 UTC</td>\n",
       "      <td>Lawmaker stormed into hearing room. See what h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_topstories/~3/8C...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>19:12:14 UTC</td>\n",
       "      <td>Trump couldn't be charged for a Fifth Avenue s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_topstories/~3/Cb...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>16:32:50 UTC</td>\n",
       "      <td>Trump photos posted on private Instagram raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_topstories/~3/lo...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>18:52:17 UTC</td>\n",
       "      <td>Only 7(!) Republican senators are ruling out r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_topstories/~3/YK...</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>19:03:53 UTC</td>\n",
       "      <td>In photos: The Trump impeachment inquiry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link published_date  \\\n",
       "0  http://rss.cnn.com/~r/rss/cnn_topstories/~3/md...     2019-10-23   \n",
       "1  http://rss.cnn.com/~r/rss/cnn_topstories/~3/8C...     2019-10-23   \n",
       "2  http://rss.cnn.com/~r/rss/cnn_topstories/~3/Cb...     2019-10-23   \n",
       "3  http://rss.cnn.com/~r/rss/cnn_topstories/~3/lo...     2019-10-23   \n",
       "4  http://rss.cnn.com/~r/rss/cnn_topstories/~3/YK...     2019-10-23   \n",
       "\n",
       "  published_time                                              title  \n",
       "0   18:09:23 UTC  Lawmaker stormed into hearing room. See what h...  \n",
       "1   19:12:14 UTC  Trump couldn't be charged for a Fifth Avenue s...  \n",
       "2   16:32:50 UTC  Trump photos posted on private Instagram raise...  \n",
       "3   18:52:17 UTC  Only 7(!) Republican senators are ruling out r...  \n",
       "4   19:03:53 UTC           In photos: The Trump impeachment inquiry  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_daily = news_df[news_df.published_date == today]\n",
    "\n",
    "news_df_daily.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
